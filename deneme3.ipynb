{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2d8784",
   "metadata": {},
   "source": [
    "## YAPBOZ CHATBOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d1e55",
   "metadata": {},
   "source": [
    "### Gerekli Ortamın Kurulumu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f80f2c",
   "metadata": {},
   "source": [
    "Gerekli Kütüphaneler:\n",
    "\n",
    "-langchain (dil modelleriyle çalışmayı kolaylaştıran modül)\n",
    "\n",
    "-chromadb (bağlama göre vektörlere çevirdiğimiz metinlerin saklandığı database)\n",
    "\n",
    "-pymupdf (pdf -> yazı)\n",
    "\n",
    "-sentence-transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19212825",
   "metadata": {},
   "source": [
    "### 1. Veri Hazırlığı (PDF parçalama ve vektörleştirme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a11ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz #pymupdf'in import edilirkenki adı (bana da saçma geldi)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da129330",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ac9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"./data/Yapboz.pdf\") # Yapbozu doc değişkenine kaydettik.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_texts = [page.get_text().strip() for page in doc]  # Her sayfayı python listesi\n",
    "                                                     # şeklinde kaydettik.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19249925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şimdi bu sayfaları da daha küçük anlamlı parçalara böleceğiz. (Paragraf->Cümle->Kelime->Harf)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1000 tokenlik parçalara ayırırken ayırma sırası paragraf cümle diye gidiyor..\n",
    "separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, # 1000 tokenlik büyüklükte parça\n",
    "    chunk_overlap = 200, # Her bir parça öncekinin son 200 tokeniyle başlayacak (anlam korunur)\n",
    "    length_function = len,\n",
    "    separators=separators\n",
    ")\n",
    "chunks = text_splitter.create_documents(pdf_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8fc16",
   "metadata": {},
   "source": [
    "Şimdi, oluşturduğumuz bu parçaları anlam ve bağlamlarına göre sayısal değerlere çevirecek\n",
    "embedding modelini kuralım. Bu da büyük bir dil modeli aslında sadece bu işlem için\n",
    "kodlanmış"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdeeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"intfloat/e5-large-v2\"\n",
    "model_kwargs = {'device':'cpu'}\n",
    "encode_kwargs = {'normalise_embeddings': False}\n",
    "hf_embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "# Şimdilik çalıştırmıyoruz, sadece kurduk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b3363",
   "metadata": {},
   "source": [
    "Sırada bize cevabı verecek modelimizi kurmakta. Şimdilik ücretsiz bir tercih olan mistral\n",
    "kullanıldı, sistem güzel çalışırsa gpt'ye geçilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "hf = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    huggingfacehub_api_token=\"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\"\n",
    "    )\n",
    "\n",
    "# Yine aynı şekil, şimdilik kurulumunu yaptık."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a111f",
   "metadata": {},
   "source": [
    "Sırada ilk başta böldüğümüz parçaların sayısal hallerini saklayacağımız\n",
    "veri tabanını kurmakta. Asıl dil modelimiz buradan aldığı verilerle bize \n",
    "bir cevap üretecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client(\n",
    "    chromadb.config.Settings(\n",
    "        persist_directory=\"./chroma_db\" # RAM e değil diske yazdırmak için.\n",
    "    )\n",
    ")\n",
    "\n",
    "collection = chroma_client.create_collection(name=\"yapboz\")\n",
    "\n",
    "# Şuanda oluşturduk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8e739",
   "metadata": {},
   "source": [
    "Bir sonraki adımlarda pdf'i böldüğümüz parçaları hf_embedding ile vektörlere çevirecek,\n",
    "bu vektörleri de oluşturduğumuz veritabanına kaydedeceğiz. Daha sonra bir prompt şablonu\n",
    "oluşturacak, bu şablona ve veritabanındaki vektörlere göre yüklediğimiz dil modeli \n",
    "bizlere bir cevap oluşturacak.."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
